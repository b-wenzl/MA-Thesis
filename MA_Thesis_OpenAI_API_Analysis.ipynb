{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Data Pre-processing"
      ],
      "metadata": {
        "id": "wrUoi_yRS7i1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Z_GRVktas3T",
        "outputId": "744dfe5f-8d17-4274-af09-00baf0cdf6e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tr9aATHgSr_w"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "file_path = '/content/drive/My Drive/MA_Dataset.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "\n",
        "# Select columns: key for analysis and additional for context\n",
        "columns = ['algorithm_id', 'name', 'organization', 'goal', 'methods_and_models', 'risks',\n",
        "           'publication_category', 'category', 'status', 'proportionality',\n",
        "           'lawful_basis', 'human_intervention']\n",
        "df_subset = df[columns].copy()\n",
        "\n",
        "# Normalize text fields for key analysis columns\n",
        "normalization_map = {\n",
        "    # Machine Learning Variants\n",
        "    'machine-learning': 'machine learning',\n",
        "    'machine learning algorithm': 'machine learning',\n",
        "    'ml': 'machine learning',\n",
        "    'ml model': 'machine learning',\n",
        "    'ml algorithms': 'machine learning',\n",
        "    'ai/ml': 'machine learning',\n",
        "\n",
        "    # Rule-Based Systems\n",
        "    'rule-based system': 'rule-based',\n",
        "    'rules-based': 'rule-based',\n",
        "    'expert system': 'rule-based',\n",
        "\n",
        "    # Decision Trees\n",
        "    'decision tree': 'decision trees',\n",
        "    'dt': 'decision trees',\n",
        "\n",
        "    # Random Forest\n",
        "    'random forest model': 'random forest',\n",
        "    'rf': 'random forest',\n",
        "\n",
        "    # Regression Models\n",
        "    'logistic regression': 'regression',\n",
        "    'linear regression': 'regression',\n",
        "    'regression model': 'regression',\n",
        "\n",
        "    # Clustering\n",
        "    'clustering algorithm': 'clustering',\n",
        "    'k-means': 'clustering',\n",
        "\n",
        "    # Natural Language Processing\n",
        "    'nlp': 'natural language processing',\n",
        "    'text analysis': 'natural language processing',\n",
        "\n",
        "    # Neural Networks\n",
        "    'deep learning': 'neural network',\n",
        "    'neural network model': 'neural network',\n",
        "\n",
        "    # Statistical Models\n",
        "    'statistical model': 'statistics',\n",
        "    'statistical analysis': 'statistics',\n",
        "\n",
        "    # Other General Terms\n",
        "    'ai': 'artificial intelligence',\n",
        "    'data analysis': 'analytics',\n",
        "    'data mining': 'analytics'\n",
        "}\n",
        "\n",
        "text_columns = ['goal', 'methods_and_models', 'risks']\n",
        "for col in text_columns:\n",
        "    df_subset[col] = df_subset[col].str.lower()  # Convert to lowercase\n",
        "    for old_term, new_term in normalization_map.items():\n",
        "        df_subset[col] = df_subset[col].str.replace(r'\\b' + old_term + r'\\b', new_term, regex=True)\n",
        "\n",
        "# normalize 'name' column for consistency (e.g., remove extra spaces)\n",
        "df_subset['name'] = df_subset['name'].str.strip()\n",
        "\n",
        "# Flag missing values for key analysis columns\n",
        "for col in text_columns:\n",
        "    df_subset[f'{col}_missing'] = df_subset[col].isna()\n",
        "\n",
        "# Save cleaned subset for API processing\n",
        "df_subset.to_csv('cleaned_algorithm_register_subset.csv', index=False)\n",
        "\n",
        "# Log pre-processing steps\n",
        "with open('preprocessing_log.txt', 'w') as f:\n",
        "    f.write(f\"Dataset loaded with {len(df)} entries and {len(df.columns)} columns.\\n\")\n",
        "    f.write(f\"Subset created with columns: {columns}\\n\")\n",
        "    f.write(f\"Missing values flagged: goal ({df_subset['goal_missing'].sum()}), \"\n",
        "            f\"methods_and_models ({df_subset['methods_and_models_missing'].sum()}), \"\n",
        "            f\"risks ({df_subset['risks_missing'].sum()})\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Prompt Design & Testing"
      ],
      "metadata": {
        "id": "HOqQ5NbaeNR0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure OpenAI is installed in your coding environment\n",
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1bw1r70mh0W5",
        "outputId": "467d35b3-3b51-4253-fade-02dee2c31433"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "print(openai.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gLsx9daWiJoR",
        "outputId": "587786bc-1a2d-41b6-9549-1569dfba7401"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.78.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# OpenAI has released new updates. Make sure you have the latest version\n",
        "!pip install --upgrade openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfF9J2OKm1cM",
        "outputId": "ebd07b16-b93b-43d8-95c2-80341843f1ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.78.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if OpenAI is successfully connected\n",
        "import openai\n",
        "\n",
        "client = openai.OpenAI(api_key=\"key\")\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "        {\"role\": \"user\", \"content\": \"Test prompt\"}\n",
        "    ],\n",
        "    max_tokens=50\n",
        ")\n",
        "\n",
        "print(\"API connection successful!\")\n",
        "print(\"Response:\", response.choices[0].message.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6tI5cbfQm9mT",
        "outputId": "09be1639-bf1d-40ca-9240-c125403def6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API connection successful!\n",
            "Response: How can I assist you with this test prompt?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This code tests the prompt by selecting 20 random entries from the entire dataset. The scoring done by GPT-4 has to be reviewed manually and any inconsistencies addressed in the prompt.\n",
        "\n",
        "import pandas as pd\n",
        "import time\n",
        "import json\n",
        "from openai import OpenAI\n",
        "\n",
        "# Initialize the OpenAI client\n",
        "client = OpenAI(api_key=\"key\")\n",
        "\n",
        "# Load your dataset\n",
        "df = pd.read_csv(\"cleaned_algorithm_register_subset.csv\")\n",
        "df = df[['name', 'goal', 'methods_and_models', 'risks']].fillna('')\n",
        "\n",
        "# Sample 20 entries\n",
        "df_sample = df.sample(n=20, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Define the scoring prompt with your full framework\n",
        "def build_prompt(entry):\n",
        "    return f\"\"\"\n",
        "You are a research assistant analyzing entries in the Dutch Algorithm Register to evaluate transparency. For each entry, read the fields “goal,” “methods_and_models,” and “risks.” Apply the following scoring framework to assign a score (0–2) for three dimensions: Goals, Logic, and Limitations. Do not use the “name” field for scoring but include it in the output for reference.\n",
        "\n",
        "Scoring Framework:\n",
        "• Goals:\n",
        "  o 0: No purpose stated or blank goal field (e.g., empty “goal” or “Used for policy”).\n",
        "  o 1: General purpose stated without specific context or policy objective (e.g., “Supports social services”).\n",
        "  o 2: Specific, contextualized purpose with clear policy objective (e.g., “Identifies children at risk of neglect for early intervention in primary schools”).\n",
        "• Logic:\n",
        "  o 0: No explanation of how the system works or blank (e.g., empty “methods_and_models” or “A model is used”).\n",
        "  o 1: Mentions at least one element (e.g., input data or model type) but lacks full process description (e.g., “Uses CRM data to cluster users”).\n",
        "  o 2: Clear explanation of inputs, process, and model type (e.g., “Combines municipal income data with logistic regression to classify households by debt risk”).\n",
        "• Limitations:\n",
        "  o 0: No limitations or risks mentioned or blank (e.g., empty “risks”).\n",
        "  o 1: Mentions a risk or limitation vaguely without specifying its nature or context (e.g., “There may be bias”).\n",
        "  o 2: Explicitly describes known risks, data biases, or contexts of inaccuracy (e.g., “Limited accuracy for undocumented residents due to data exclusion; may reinforce historical biases”).\n",
        "\n",
        "Instructions:\n",
        "1. Assign a score (0, 1, or 2) for Goals, Logic, and Limitations based on the text in the respective fields.\n",
        "2. Provide a one-sentence justification for each score, explaining why the score was assigned based on the text.\n",
        "3. If a field is blank or missing, assign a score of 0 and note the absence in the justification.\n",
        "4. Output the results in the following JSON format:\n",
        "{{\n",
        "  \"name\": \"{entry['name']}\",\n",
        "  \"goals_score\": <0–2>, \"goals_justification\": \"<reason>\",\n",
        "  \"logic_score\": <0–2>, \"logic_justification\": \"<reason>\",\n",
        "  \"limitations_score\": <0–2>, \"limitations_justification\": \"<reason>\"\n",
        "}}\n",
        "\n",
        "Entry:\n",
        "Goal: {entry['goal']}\n",
        "Methods and Models: {entry['methods_and_models']}\n",
        "Risks: {entry['risks']}\n",
        "\"\"\"\n",
        "\n",
        "# Run GPT-4 on each entry\n",
        "results = []\n",
        "\n",
        "for i, row in df_sample.iterrows():\n",
        "    prompt = build_prompt(row)\n",
        "    print(f\"Processing entry {i+1}/20...\")\n",
        "    try:\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                {\"role\": \"user\", \"content\": prompt}\n",
        "            ],\n",
        "            temperature=0,\n",
        "        )\n",
        "        result = response.choices[0].message.content\n",
        "        results.append(json.loads(result))\n",
        "        time.sleep(1.5)\n",
        "    except Exception as e:\n",
        "        print(f\"Error on entry {i+1}: {e}\")\n",
        "        continue\n",
        "\n",
        "# Save results\n",
        "df_results = pd.DataFrame(results)\n",
        "df_results.to_csv(\"gpt4_transparency_scoring_sample.csv\", index=False)\n",
        "print(\"All done. Results saved as 'gpt4_transparency_scoring_sample.csv'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqZKVHsrqTwR",
        "outputId": "9488ec01-d7bf-4a8c-cac8-9e26878e6a13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing entry 1/20...\n",
            "Processing entry 2/20...\n",
            "Processing entry 3/20...\n",
            "Processing entry 4/20...\n",
            "Processing entry 5/20...\n",
            "Processing entry 6/20...\n",
            "Processing entry 7/20...\n",
            "Processing entry 8/20...\n",
            "Processing entry 9/20...\n",
            "Processing entry 10/20...\n",
            "Processing entry 11/20...\n",
            "Processing entry 12/20...\n",
            "Processing entry 13/20...\n",
            "Processing entry 14/20...\n",
            "Processing entry 15/20...\n",
            "Processing entry 16/20...\n",
            "Processing entry 17/20...\n",
            "Processing entry 18/20...\n",
            "Processing entry 19/20...\n",
            "Processing entry 20/20...\n",
            "All done. Results saved as 'gpt4_transparency_scoring_sample.csv'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Analysis of Entire Dataset in Batches"
      ],
      "metadata": {
        "id": "bD6yYPO9sD4v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import time\n",
        "import json\n",
        "from openai import OpenAI\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Setup\n",
        "client = OpenAI(api_key=\"key\")\n",
        "batch_size = 25  # You can lower to 20 if hitting limits\n",
        "\n",
        "# Load data\n",
        "df = pd.read_csv(\"cleaned_algorithm_register_subset.csv\")\n",
        "df = df[['name', 'goal', 'methods_and_models', 'risks']].fillna('')\n",
        "\n",
        "# Helper: Build prompt for one entry\n",
        "def build_prompt(entry):\n",
        "    return f\"\"\"\n",
        "You are a research assistant analyzing entries in the Dutch Algorithm Register to evaluate transparency. For each entry, read the fields “goal,” “methods_and_models,” and “risks.” Apply the following scoring framework to assign a score (0–2) for three dimensions: Goals, Logic, and Limitations. Do not use the “name” field for scoring but include it in the output for reference.\n",
        "\n",
        "Scoring Framework:\n",
        "• Goals:\n",
        "  o 0: No purpose stated or blank goal field (e.g., empty “goal” or “Used for policy”).\n",
        "  o 1: General purpose stated without specific context or policy objective (e.g., “Supports social services”).\n",
        "  o 2: Specific, contextualized purpose with clear policy objective (e.g., “Identifies children at risk of neglect for early intervention in primary schools”).\n",
        "• Logic:\n",
        "  o 0: No explanation of how the system works or blank (e.g., empty “methods_and_models” or “A model is used”).\n",
        "  o 1: Mentions at least one element (e.g., input data or model type) but lacks full process description (e.g., “Uses CRM data to cluster users”).\n",
        "  o 2: Clear explanation of inputs, process, and model type (e.g., “Combines municipal income data with logistic regression to classify households by debt risk”).\n",
        "• Limitations:\n",
        "  o 0: No limitations or risks mentioned or blank (e.g., empty “risks”).\n",
        "  o 1: Mentions a risk or limitation vaguely without specifying its nature or context (e.g., “There may be bias”).\n",
        "  o 2: Explicitly describes known risks, data biases, or contexts of inaccuracy (e.g., “Limited accuracy for undocumented residents due to data exclusion; may reinforce historical biases”).\n",
        "\n",
        "Instructions:\n",
        "1. Assign a score (0, 1, or 2) for Goals, Logic, and Limitations based on the text in the respective fields.\n",
        "2. Provide a one-sentence justification for each score, explaining why the score was assigned based on the text.\n",
        "3. If a field is blank or missing, assign a score of 0 and note the absence in the justification.\n",
        "4. Output the results in the following JSON format:\n",
        "{{\n",
        "  \"name\": \"{entry['name']}\",\n",
        "  \"goals_score\": <0–2>, \"goals_justification\": \"<reason>\",\n",
        "  \"logic_score\": <0–2>, \"logic_justification\": \"<reason>\",\n",
        "  \"limitations_score\": <0–2>, \"limitations_justification\": \"<reason>\"\n",
        "}}\n",
        "\n",
        "Entry:\n",
        "Goal: {entry['goal']}\n",
        "Methods and Models: {entry['methods_and_models']}\n",
        "Risks: {entry['risks']}\n",
        "\"\"\"\n",
        "\n",
        "# Run GPT-4 over the full dataset\n",
        "all_results = []\n",
        "\n",
        "for idx in tqdm(range(0, len(df), batch_size)):\n",
        "    batch = df.iloc[idx:idx+batch_size]\n",
        "\n",
        "    for i, row in batch.iterrows():\n",
        "        prompt = build_prompt(row)\n",
        "        try:\n",
        "            response = client.chat.completions.create(\n",
        "                model=\"gpt-4\",\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "                    {\"role\": \"user\", \"content\": prompt}\n",
        "                ],\n",
        "                temperature=0\n",
        "            )\n",
        "            result = response.choices[0].message.content\n",
        "            all_results.append(json.loads(result))\n",
        "            time.sleep(1.5)  # Respect rate limits\n",
        "        except Exception as e:\n",
        "            print(f\"Error at row {i}: {e}\")\n",
        "            continue\n",
        "\n",
        "# Save results\n",
        "df_results = pd.DataFrame(all_results)\n",
        "df_results.to_csv(\"gpt4_full_transparency_scoring.csv\", index=False)\n",
        "print(\"All entries processed and saved to gpt4_full_transparency_scoring.csv\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HhJT0O2tumQK",
        "outputId": "12a71dc6-9593-4e36-ce38-7b25449fddb1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 35/35 [2:17:50<00:00, 236.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "All entries processed and saved to gpt4_full_transparency_scoring.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}