name;goal;goals_score;Justification;methods_and_models;logic_score;Justification;risks;risks_score;Justification
emptying underground waste containers;The aim is to predict as best as possible when a container needs to be emptied. This is to avoid unnecessary trips by the drivers, but also to avoid containers being full and residents not being able to dispose of their waste. ;2;Specific, contextualized purpose with clear policy objective. ; The number of times a rubbish card is read by the device at a container is tracked. The moment this number reaches a certain limit, the container is included in a driver's driving route.;2;Clearly states the process and input data. ; Failures of the system are monitored. Periodic inspections of the containers take place. In addition, anonymised household waste passes are used. As a result, it cannot be traced which residents deposit waste in a container. ;1;Some limitations are suggested but not contextualized or explained. 
passport for work;Passport for Work aims to help people distant from the labour market find sustainable jobs. To do so, it uses online tools, gamification, applied market research and mobile micro-learning. Passport for Work gives residents and businesses additional opportunities and support to find suitable work or employees.;2;Specific, contextualized purpose with clear policy objective. ;"
Below is the functional explanation of how the algorithm works.
 


Algorithm to determine a job seeker's skill profile: Passport for Work maps job seekers' skills through a combination of self-assessment, neurogames and online role plays. Based on these tests, the algorithm determines the skill profile. This is a schematic overview of a jobseeker's skills.




Skill profile of professions and jobs: Each profession within Passport for Work has its own skill profile. This skill profile consists of an overview of competences a candidate must have for that profession. An employer can enter a vacancy for a particular profession. The employer can adopt the skill profile for that profession one-to-one or modify the profile.




Matching algorithm: The matching algorithm first looks at hard requirements such as possession of a driving licence, commuting distance or available working days. These are the so-called 'knock-out criteria'. But most importantly, it assesses whether a jobseeker has or can develop the skills that go with the job. The algorithm looks at how far a jobseeker's profile matches the job profile. It does this based on a weighting matrix. This translates the results of the tests into a score on each of the competences from the O*NET system. The highest score means the competency matches exactly what is needed. The score for all competences together determines a person's possible suitability for a profession and job. The degree of possible suitability is indicated from most suitable to least suitable always showing all results.


";2;Clear explanation of inputs, process, and model type. ;"

Circumstances while completing the tests can have a negative impact on the outcome. For example, if the job seeker is disturbed, unable to concentrate properly, the computer or the internet is not working properly, then the conclusion may be wrongly drawn that the job seeker is not fast enough and therefore receives a lower rating.


Subjectivity or cultural influence: The matching system is based on current knowledge within psychometrics. However, cultural influences or subjectivity cannot be ruled out. The likelihood of such effects is difficult to estimate, but if they occur, they can have negative consequences for those involved.


Incorrect matching: There is a chance that, due to bugs or unforeseen issues, the measured competences or the calculation of the match is not correct. Then the outcome may be a less appropriate advice.


Limited matching: Passport for work cannot advise towards occupations and/or sectors not included in Passport for Work. As a result, jobseekers may miss out on an opportunity for (better) suitable work.

";2;Risks are explicitly defined. 
chatbot - environment act (ai - version);Support customer service. Assist residents in an inclusive way with their questions on the topic of the Environment Act. ;2;Specific, contextualized purpose with clear policy objective. ;"FeedAdministrator enters sources via the underlying management platform that will serve as feeds for the answers.  The sources are read in by OpenAI and used to generate an answer via a language model. The Chatbot user asks a question. The Chatbot sends question to OpenAI for analysis. OpenAI sends answer back to bot for further processing. Sent information is deleted after 30 days. Within that period, administrator can analyse them for:Improve the filling of the knowledge base;To prevent misuse of the bot. Data is neither used for further training of the language model nor resold.";2;Logic is mentioned as well as model type,;"We estimate the risk is low. People are warned not to enter personal data. The sources for the bot are verified documents. There is a risk that the chatbot gives a wrong answer based on the source documents. We mitigate this problem also called hallucinating by:monitoring the chatbot;placing a caveat on the website.A pre-DPIA was carried out for this application which revealed that no DPIA was needed.";2;Risks are explicitly defined and it is mentioned how they are mitigated. 
camera surveillance traffic measure (closed);Goal is to digitally enforce the local closure (traffic measure). Sub-goal Ringdijk: making embankment more car-free. The software is programmed to recognise and photograph the license plates of motor vehicles that pass the prohibition on entering the road. The software then ensures that the photo of the passage i.c.w. date, time, location and vehicle data is submitted to our enforcement system for evaluation.  Impact: a license plate is recognised and registered. Based on control/algorithm, a boa (special investigating officer) is shown a selection of license plates of motor vehicles that are (possibly) in violation. The consequences range from nil to significant (being fined or not).;2;Specific, contextualized purpose with clear policy objective. ;Image recognition. ANPR cameras at four different locations record motor vehicle license plates. The algorithm checks whether an exemption has been granted and determines whether photos are submitted for evaluation in the enforcement system. The vehicle data are enriched in the enforcement system through a link with the RDW.;2;The model type and process are clearly explained. ;Because personal data is processed, extra attention is paid to security. All data is processed in a secure environment.Security measures are contractually laid down in section 4.10 of the Service Level Agreement with supplier Sigmax.Only boas of the municipality and employees with a designation to view police data are given access to the data of observed offences. Data from other vehicles are also shielded from them. Deviations are reported directly to the supplier.;1;Risks vaguely mentioned but not specified or contextualized. 
digital applications for civil affairs;The purpose of the algorithm is to help residents and business owners with digital applications or returns. The algorithm processes certain applications and returns completely automatically. The algorithm checks the resident's data. Only if the municipality needs more data or checks or actions are required, a civil affairs employee jumps in. The algorithm can only approve an application or declaration. Only the civil affairs employee can reject it. Use of the algorithm is never negative for the resident.Residents who prefer not to submit their applications digitally are still welcome at the counter. For example, when residents are not good with computers.;2;Specific, contextualized purpose with clear policy objective. ;Through the municipality's website, a resident or entrepreneur applies for a digital product or service. While filling in, the algorithm already checks whether the application is in accordance with the laws and regulations. A fully completed digital application or declaration appears on a work list at the municipality's civic affairs department. An employee evaluates the application and processes it.The municipality can choose which applications the algorithm may handle automatically and which must always be handled by an employee. ;1;Input data is vaguely mentioned. Process is described but lacks explanation of algorithmâ€™s logic.;;0;Field left empty. 
traffic model accessibility control;The purpose of the model is to see the impact on traffic flow of a single activity or the relationship between multiple activities in a modelled and abstracted environment. A citizen does not directly interact with the algorithm. If a citizen uses public space as a participant in traffic and there are diversions, the citizen notices that the algorithm has been used to arrive at the best possible diversion with the least possible inconvenience. ;2;Specific, contextualized purpose with clear policy objective. ;This is an internally used model serving as input for discussions with the initiators of construction works, road works and events to take measures to ensure adequate traffic flow as well. It is an objective calculation to support the traffic engineering test for potential bottlenecks created by activities in the city (construction works road works and events). This model provides an estimate of where, given these activities and traffic flows, there may be bottlenecks. This provides input for coordinating with the initiators of the activities so that the (diversion) routes continue to function adequately. The output (nuisance) is qualified in terms of the number of people inconvenienced, travel time delays, waiting times, etc. ;2;Input and output data including the decision are clearly described. ;There are no specific risks in terms of privacy issues around personal data. Bias does not play a role.  ;1;Risks are vaguely mentioned but not specified or contextualized. 
pressure measurement - group dynamics estimation;"It was a pilot. The algorithm recognises whether a (moving) object is a human or not and determines the speed for each person. It then assigns a classification to this situation, such as ""stationary"", ""agitated"" or ""panic"". The aim is efficient enforcement on crowds. The algorithm is not intended to recognise people or do anything with personal data.";2;Specific, contextualized purpose with clear policy objective. ;"The algorithm detects people and their speed of movement. The algorithm recognises whether a (moving) object is a human or not and determines the speed for each person. It then assigns a classification to this situation, such as ""stationary"", ""agitated"" or ""panic"".";2;Input and output data is described, logic is mentioned. ;A DPIA has been carried out (DPIA pressure measurement and group dynamics) describing the risks and measures. There is no bias as the dynamics are determined without preference on types of people. The choice of where to hang the cameras was made together with the enforcers. ;1;Risks are vaguely mentioned. 
benefit recipients legality prediction;"The model made a prediction for the chance of unlawfulness or legality, by looking at the data known in the administration of citizens whose legality had been investigated in previous years. The conclusion may have been that the benefit was paid out lawfully; or that the previously paid out benefit did not match the actual situation (unlawfulness). Based on this historical data, a prediction can be made about the chance of legality or illegality for current benefit recipients. This prediction is therefore made on the basis of the data known in our administration of current benefit recipients. The outcome of the model is a 'risk assessment number' that varies between 0 (high chance of legality) and 1 (high chance of illegality). The benefit recipients with the highest risk assessment number are invited for an investigation interview, unless, for example, an investigation into legality has already taken place recently. The number of benefit recipients invited is determined annually on the basis of the risk assessment model. The model has been developed anew every year, because new research data becomes available every year. The information from recent studies into legality has therefore always been included in the development of a new model. The municipality of Rotterdam has not used this algorithm since the beginning of 2022. Our exploration into an improved 'risk model' has shown that it is currently not possible to develop an algorithm that fits within our policy.";2;Specific, contextualized purpose with clear policy objective. ;The municipality of Rotterdam no longer uses this algorithm. The exploration of an improved 'risk model' has shown that it is currently not possible to to develop an algorithm that fits within our policy. When the algorithm was still in use, the following description applied: The Department of Work & Income (W&I) regularly checks whether residents are entitled to benefits and whether these still match their situation. Benefit recipients can therefore be invited for an interview. To determine who receives an invitation, the municipality uses various selection methods, including a risk algorithm. This algorithm helps the municipality to estimate which benefit recipients are most likely to receive benefits that no longer match their situation. This has two advantages for society: 1) This helps the municipality to prevent overpayment. 2) In addition, benefit recipients who are less likely to have special circumstances are less likely to be invited for an interview. The risk assessment algorithm works predictively. This algorithm uses data that the W&I department needs to perform its tasks and to be able to pay out the benefit. This involves data such as the amount of the benefit and the family situation. But also the skills and qualities of the job seeker, which give you more chances on the labour market. This comes from two data sources: 1) Socrates: the benefits administration system. This determines and records the amount of benefits provided. This system contains data on, for example, the living situation of the benefit recipient. 2. RWM/Raak: system in which data on the reintegration of job seekers is recorded. The municipality only uses data from its own administration. There is no link with other data files. The risk assessment algorithm is only used to invite benefit recipients for an interview. The algorithm does not make a statement about whether the benefit is justified. An employee of the department assesses whether there is a right to a benefit. This depends on your data and this is different for everyone.;2;Model type, input data and logic clearly described. ;To determine the risk of an algorithm, the municipality of Rotterdam uses a fixed classification model. The risk assessment model has been designated as a high-risk algorithm. The municipality is therefore taking additional safety measures. These include measures that ensure that the development and use of the model is properly supervised. For example, specific attention is paid to the ethical risks and an external supervisory committee monitors the design and use of the model. This committee is expected to be in place at the beginning of 2022. If an algorithm is in the high-risk category, a human test is part of the work process in which the algorithm in question is used. The chance of bias is limited because the risk assessment model is only used to determine who receives an invitation for an investigation interview. The algorithm does not determine whether someone is lawfully or unlawfully receiving benefits. This is done by income consultants from the W&I department. They conduct extensive research into the situation, together with the benefit recipient. After all, providing benefits is tailor-made and is done at an individual level.;2;Risks are clearly described and contextualized. 
information supported decision - short-stay (schengen) visa (cdv);"The algorithm is used to support the processing of Short Stay Visa applications within Schengen countries. In doing so, the Ministry of Foreign Affairs (BZ) implements the government task assigned to BZ.The IOB contributes to the assessment process of short-stay Schengen visas for the purpose of promoting economic diplomacy, family visits and tourism and preventing any threats to public order, security and settlement.The visa application is assessed using the following information: (1) information submitted by the applicant himself to BZ; (2) information from the sponsor and/or employer; (3) information from the migration chain (see under 'data sources'); and (4) information from profiles based on similar past applications.The conditions for obtaining a visa are and will remain the same for everyone, regardless of previous applications or those for which a sponsor has stood as guarantor. These conditions have been agreed between Schengen countries and laid down in the EU Visa Code. The use of the algorithm is supportive for deciding on an application, but never a ground for refusing a visa. The impact of using the algorithm is therefore minimal.";2;Specific, contextualized purpose with clear policy objective. ;Comparison with the data present is done through the so-called hit/no hit principle. If there is information about the applicant, the sponsor or the employer in the BZ database, there is a hit. There is therefore a match between the information entered on the application form and the information known to BZ from the database. In addition, the application is compared with the profiles present. Here too, the hit/no hit principle is used. Here, the characteristics of the profile are compared with the specific characteristics from the application form. For example, the purpose of travel and the place where the visa application was submitted. When there is a match between the characteristics from the profiles and the application form, there is a hit. A profile is set of characteristics established after an analysis of historical data available at BZ. It is not a personal profile that says something about an individual, but about a similar (large) group of visa applicants. Profiles are established by BZ after careful analysis. For instance, profiles must meet various conditions before they are deployed by BZ.The algorithm is classified as a classification system and works on the basis of predetermined simple 'if-then rules'.;2;Input data and logic are clearly described. ;Final decisions on an application are monitored by BZ. These decisions are compared with the supporting advice given by the algorithm. This monitors whether decision-makers do not 'blind' to the algorithm's treatment advice by automatically basing an approval or a rejection on it. ;1;Mitigation of risks mentioned without specifying the risks. 
cryptshare;The purpose of this algorithm is to help ensure that information sent by e-mail is properly secured. In other words: not with too few security measures, but not with too many either. The algorithm contributes to this by alerting e-mail senders to sensitive information and encouraging them to then send this information securely. If they choose to do so, the e-mail is secured with encryption, two-factor authentication for the recipient, revocation option and logging.This ensures that sensitive information is secured, while insensitive information can be accessed without additional friction for the recipient. The algorithm only impacts the process of sending e-mails and does not affect the substantive legal status of citizens or businesses.;2;Specific, contextualized purpose with clear policy objective. ;When composing a new e-mail, the terms in the message and attachments are used to see how similar it is to previously (securely or normally) sent e-mails. If the e-mail is sufficiently similar to messages normally sent securely, the e-mail is flagged as potentially sensitive. Based on the terminology in the e-mail, it is determined whether it relates to a specific category of sensitive information, such as medical or legal. The moment the e-mail is classified as sensitive and is about a topic that the organisation has set to be sent securely, the user is given a recommendation to send the e-mail securely. ;2;Input data and logic are clearly described. ;The overall performance of the algorithm is monitored by the vendor. If it turns out that the algorithm is making incorrect classifications more often, this is picked up by the monitoring so that adjustments to the algorithm can be made. For the using organisation, the accuracy of Smart Classification is also visible in an administrator dashboard.;2;Mentions risks of incorrect classifications. 
income settlement assistance (oib) signal;"Does someone have an assistance benefit and also income from work or another benefit?Then, according to the Participation Act, this income must be offset against the social assistance benefit. Sometimes this income even has to be repaid.The Income Settlement Assistance (OIB) signal helps municipalities with this. It provides insight into extra income of people with social assistance benefits. Municipalities can thus ensure that:all extra income (including corrections) is known;the correct amount is deducted from the benefit.With this information, municipalities can work faster. For people on welfare benefits, the advantage is that they can better estimate how much income they have. They are also less likely to have to repay money.";2;Specific, contextualized purpose with clear policy objective. ;"Provision to municipalities (F):- BSN- gsd code- File code- Household type- Legal basis- start-date-ukp- end-date-ukp- start-date-ikv- end-date-ikv- lb number- adm unit-name- liable to income (type of employment contract)- Compulsory income description- type-income relationship- type-income-relationship-description- start-date-lp- end-date-lp- paid-hours- pay-sv- pay-in-money- value-not-paid-in-money- inh-svp premium- inh-svvpremium-normal- inh-svvpremium-special- value-use-car- inh-lbph- wage-lbph- Inh-WGA/WHK-ind- Inh-WGA-WHK-ind-normal- Inh-WGA-WHK-ind-normal- wage-lbph-normal- wage-lbph-special- inh-lbph-normal- inh-lbph-special- net wage-subtotal- net wage-normal- net-wage-subtotal- net ANW benefit- net ANW- income-net-ind-excl-claim-vt- ind-claim vt- income-netind-incl-claim-vt- income-netind-special- holiday allowance-paid- holiday allowance accrued-right- accrual-awwb- take-up-awvb- net-wage-ind-vt- net-wage-ind-avwb- ind-loonhk- applied payroll tax table- applied-wage-tax-table-sort-table- applied-payroll tax table-colour table- applied-payroll tax table-payroll period- applied-wage-tax-table-special-significance- ad-unit-address- ad unit-postal code- ad-unit-location- TagSignal type- TagMultipleIKV- TagAlternativeCalendar month- TagBenefitsPayment- TagStartStopPayment- TagWageInNature- TagCalculateBT- TagFirstPensionPayment- TagManualCalculation- TagPrivateUseCarExplanation:A. The municipality's benefit file;B. The application to UWV based on the municipality's benefit file;C. The delivery of UWV's file of Citizen Service Numbers (BSN) with data on income, pensions and/or benefits;D. Annually, the IB retrieves the following additional (indexed) data.- The percentage to be determined annually by which the wage to be offset may be reduced on the basis of indicative WGA/WHK withholding (this percentage is based on the average WGA levy percentage published annually by the UWV, which is multiplied by factor 3). 50% of this then applies as a percentage deduction WGA/WHK from net salary.- Height of fixed amount of ANW benefit (source: SZW, Decree on ANW benefit)- The level of the fixed amount of the Young Disabled Persons Allowance (source: Tax and Customs Administration)- Tables holiday allowance entitlement (source: SZW, Regulation Participation Act, art. 11-13)- Payroll tax tables per year (source: Belastingdienst)NB. These are public (publicly accessible) data, they are not personal data.E. The IB compares the response file received by UWV with previous month and applies logic to only provide municipalities with new and/or wage bill changed income statements, enriched with a net indicative (normal and special) income calculated by IB that is as close as possible to the amount to be deducted from benefits in accordance with the Participation Act. The response report also contains all the amounts used to calculate this income. Finally, information labels (tags) are given so that the information can be processed as efficiently as possible by the municipality. The signal information is stored (temporarily) within national facility within the IB;F. Of the new and/or changed income declarations found, the IB issues a signal to the municipality.";2;The logic, input data and model type are clearly described. ;Citizen privacy is a major concern. That is why we periodically check whether there are risks and what can be done about them. This is called privacy impact assessment (PIA).;1;Mentions privacy risk, but not specifying the context. 
citizen affairs e-services;"The aim of the e-services with the underlying algorithm is to provide maximum support/ guidance to residents and entrepreneurs when submitting a digital application. As a result, this application can be submitted correctly and completely. The algorithm checks various data of the resident. If no additional data is required from the resident and no manual actions or checks by the municipality are required (such as signature, for example) to process the application, it can be processed without the intervention of a civic affairs officer. However, if additional data, checks or actions are required, the application/declaration always enters a work list. There, it is checked by a civil affairs employee. The algorithm can only automatically approve an application/declaration. Only the civil affairs officer can reject an application/declaration.The impact is that such an application can be dealt with efficiently by the municipality; after all, a resident/company has already carried out several steps (work), leaving the official more time for the special and/or complicated declarations/applications the municipality receives. In some cases, this application can even be processed fully automatically. The quality of service goes up because of these services, as does the quality of the data in the BRP.";2;Specific, contextualized purpose with clear policy objective. ;Through the municipality's website, a resident or entrepreneur can start an e-service. Each application is already checked against the laws and regulations applicable to the application while it is being filled in. A fully completed digital application/declaration is placed on the work list in iBurgerzaken for assessment and processing by a civil affairs employee. When an application or declaration is opened on the worklist, it is visible to the civil affairs employee which check a notification has produced, for correct assessment and processing. For a number of digital applications, a municipality can choose whether iBurgerzaken, may process them automatically without the intervention of a civil affairs employee. iBurgerzaken processes an application fully automatically if no check results in a warning. In addition, the municipality can also choose in which situations the application always appears on the work list for assessment and processing. For example, in Relocation within the Netherlands: if there is overcrowding at the new address.;2;Explains input and process. Model type not stated but logic is described. ;See human intervention. In case of a rejection, it is always the civic affairs officer who does it and never the algorithm.;1;Risks are not explicitly stated. 
sounding language;" Improve texts in clear &amp; understandable language. Better communication to citizens and businesses.";1;General purpose stated without specific context or policy objective. ;The Sounding Language application is a plug-in in Word. It only checks the written text for grammar and writing style at the explicit request of the author in order to convert it to B1 level. It checks on the basis of 6 basic modules: Expensive words, technical terms, passive sentences, long sentences, complex sentences and long paragraphs.;2;Explains input and process. ;Klinkende Taal does not use generative AI. For the deployment of this particular tool, the Osse principles for using generative AI apply and should be followed.;1;Risks not explicitly mentioned. 
calculation method decline in value;Purpose: To calculate the amount of compensation the IMG should pay out for a property for which a depreciation allowance has been applied for.Impact: The property's WOZ value and sale price are important for the depreciation compensation. In addition, the location of a property and the quakes that have occurred in this area over the years are considered. Based on all this data, the algorithm calculates the decrease in value of a property. ;2;Specific, contextualized purpose with clear policy objective. ;All postcodes within the valuation area have been classified into severity categories. The severity category is determined by the quake history within a postcode area. For the calculation of the decrease in value, the WOZ value of the property serves as a starting point. Once the severity category of the property has been determined, compensation is calculated on the basis of a severity category matrix and a compensation matrix.;2;Explains input data and logic clearly. Model type also mentioned. ;We evaluate the risks in accordance with our privacy policy. Based on this evaluation of, we take or adjust additional measures. The next update for the risks of this algorithm is scheduled for in Q4 2024.;1;No risks explicitly mentioned. 
input help business activities 2.0;The goals are:1. The registration of a sole proprietorship for start-ups has been extended with the Input Help. This allows the start-up to independently prepare a unified, structured activity description through question-and-answer with artificial intelligence.2. Simplify the translation of business activities into SBI codes for the KVK employee. Because the supplied texts are of higher quality and suggestions for appropriate SBI codes are made, classification can be faster and easier and the registration interview can be about starting the business.;2;Specific, contextualized purpose with clear policy objective. ;Entrepreneur completes activity descriptionA spell check is performedInput help checks whether there are multiple activities in the description Activity description is classified and shows 3 most appropriate SBI code (with certain certainty) for the branches construction, web shops and health careFor the other branches, the entrepreneur gets a short description of the proposed/classified SBI code (summary of the data from CBS). This is followed by a question to check whether this is correct. If yes: entrepreneur continues with own activity descriptionEntrepreneur is still free to modify the proposed activity description.;2;Input data and logic are mentioned. ;There is no automated decisionThere is no processing of personal dataThe process is monitored for Customer Satisfaction (CSAT) and Customer Effort Score (CES);1;No risks explicitly mentioned. 
population forecast model;The aim is to understand the (possible) future development of The Hague's population by age.The model has no direct impact on citizens' daily lives. ;2;Specific, contextualized purpose with clear policy objective. ;Based on the assumption of the (corrected) probabilities, the forecast for the first year by age and sex is prepared by first determining the correction for domestic departure, after which the total departures domestic and foreign are determined. To then determine the number of births, first settlement, departure, both domestic and foreign, and mortality are calculated, after which the total number of births can be calculated. Once the number of births is calculated, these are zeroed out and divided by sex. The process then determines departures again, inflows and deaths. The final step is the initial population by age and sex plus settlement by age and sex minus departure by age and sex minus mortality by age and sex. This last cycle yields the final population of the first forecast year. This population is the starting population of the second forecast year. In this way, the forecast is calculated the set number of years ahead. Using the correction matrix, it is possible to recalculate the forecast with a changed assumption.;2;Input data, logic and model type clearly described. ;Results of the model are always analysed by specialists. Annually, the results of the forecast are compared with the realisation.;1;No risks explicitly mentioned. 
dido;DiDo (Data in Data out) is about fast and automated reading of tables from suppliers into the Operational Data Layer (ODL) of a Postgres database. The ODL aims to organise uniform and reliable storage of the data provided by data suppliers. The supplier provides one-off or more frequent tables in .csv format (separated by semicolons). Those tables are read into Postgres based on a configuration file. Documentation is also generated that can be included in the project's wiki.;2;Specific, contextualized purpose with clear policy objective. ;DiDo facilitates the user in storing data in the Datawarehouse and creating documentation on that data. DiDo has two phases: Data and Documentation Definition. This is (in theory) a one-off event in which the data is defined according to a set pattern, stored in Postgres tables and filed away as Wiki documentation.Reading data into the database. Once the tables are defined, the data can be delivered. Deliveries are stored in the table, along with the data quality. The delivery is documented and can be stored in the Wiki.  There are also a number of utilities that simplify dealing with suppliers and deliveries in the database.  ;2;Input data and decision logic clearly described. ;Risk management is covered by MinBZK's standard Responsible Disclosure Statement, available at https://github.com/MinBZK/DiDo/security.;1;No risks explicitly mentioned. 
text analysis;Support in the review process where legal protections apply to information disclosed. Protection from the AVG (persons) and Woo laws (especially company confidential), where grounds for exception are named.;2;Specific, contextualized purpose with clear policy objective. ;Texts are recognised on the basis of Named Entity Recognition (NER) and a process within Insights extracts the names for further processing towards the management interface and the automatic lacquer rules. ;2;Input data and model type clearly described. ;There is no risk of automated decision-making and the algorithm has no impact on fundamental rights because the algorithm does not make decisions with legal consequences. It only makes a proposal for anonymising personal data. The municipal employee always makes the final check whether a document is correctly anonymised. ;1;No risks explicitly mentioned. 
textimprovementtool;Texts are published by employees. The functionality helps staff to produce texts that are understandable to citizens. ;1;General purpose stated without specific context or policy objective. ;As an employee, you can enter a text and then get a suggestion for a better text at the press of a button. The tool corrects language mistakes, changes the language level (A2, B1 and so on), makes suggestions for titles and can make other improvement suggestions.;2;Input and process are clearly described. ;;0;Field left empty. 
risk indicators money laundering properties;In practice, it happens that Utrecht properties are used for laundering criminal assets. By applying this algorithm, we want to gain insight into the risk of real estate being used for money laundering. With the aim of preventing and enforcing money laundering of (criminal) money as much as possible. The analysis reveals what proportion of real estate per neighbourhood was purchased with unexplained assets. ;2;Specific, contextualized purpose with clear policy objective. ;;0;Field left empty. ;The Utrecht data scientists, Information and Process Advisors (IPA) and Decentralised Information Security Officers (DISO) within the Utrecht municipality have a controlling and monitoring role in the application of the algorithm, in addition to the employees directly involved. By doing so, we want to prevent the following risks from occurring:- data leak by making personal data of Utrecht residents publicly available- algorithm takes a decision completely independently, without the intervention of an employee and without interpreting the relevant context of the situation- 'function creep' regarding data when applying the algorithm, causing the algorithm to give a distorted picture of what is going on. This can occur because the same type of data is used when applying the algorithm, and the algorithm uses that as confirmation of what comes out as information;2;Risks explicitly mentioned and contextualized. 
centric environment: charges calculation;"
Objective:
Fees are fees for municipal services. Fees are set by the municipal council and are contained in the Fees Ordinance. To levy fees, we determine base types and fee types. Fees are calculated on a basis. The base type determines where the base for the fee calculation can be found. 
 
We use Centric Environment software to process all our permit applications (including supervision and enforcement). This includes, for example, a (permit required) renovation, an environmental permit or a parking permit. 
 
Impact : 
The fee amounts for these applications are calculated on the basis of calculation rules entered by the municipality in Centric Environment. 
";2;Specific, contextualized purpose with clear policy objective. ;The algorithm calculates what fees are applicable based on the data in the application.  The employee then does a check and after this we send the invoice. ;1;Process vaguely described. ;The risk of erroneous dues amounts being charged is zero due to the combination of the algorithm with human intervention. ;1;Risks are vaguely mentioned. 
detect risks on goods infringing intellectual property rights;This algorithm focuses on declarations of goods entering or leaving the European Union, via the territory of the Netherlands. The algorithm focuses on Customs checking whether the goods infringe intellectual property rights. Regulation 608/2013 sets out how Customs acts. The regulation includes the conditions for action by Customs when goods are only suspected of infringing intellectual property rights and what measures should be taken against goods found to infringe.Based on the results, Customs will inspect companies more, or less. By using this algorithm, declarations are handled more efficiently, resulting in quicker checks and possibly quicker releases.;2;Specific, contextualized purpose with clear policy objective. ;The algorithm consists of decision rules created in collaboration with content experts. These decision rules provide estimates of which declarations have a higher risk of infringing intellectual property rights. These decision rules are based on 'if-then-else' combinations. An example: if (if) the information we have on a shipment shows that the goods have an abnormal weight, (then) the declaration is checked manually and the shipment may be selected for extended inspection. If the goods do not have an abnormal weight (else), we do not stop the shipment. Or at least not based on this criterion.;2;Process and logic clearly described.;A risk profile is always developed and checked by at least two customs staff before use. This is the 4-eye principle. And once the profile is in use, the number of declarations that produce a match is checked periodically for a profile. If necessary, the profile can be adjusted. Annually, Customs evaluates per profile whether it is necessary to refine, extend or terminate it. Customs monitors internal and external complaints and incidents, for example if a profile generates unjustified raking and therefore designates too many declarations as higher risk.;2;Risks are clearly stated. 
advising on data breach notification;The algorithm helps objectively determine whether a data breach should be reported to the Data Protection Authority and to data subjects.;2;Specific, contextualized purpose with clear policy objective. ;Step 1: The algorithm works for all kinds of countries around the world. A jurisdiction is chosen (the Netherlands). For the Netherlands, the rules as drawn up by the Personal Data Authority (AP) are considered.Step 2: An employee indicates in the system whether there was actually an incident where personal data was leaked.Step 3: An employee indicates the likelihood of harm to data subjects.Step 4: And employee indicates the extent of the impact to data subjects. Based on this information, it is determined whether the AP should be informed (if there is a chance of harm) and whether data subjects should be informed (if the impact for data subjects is high).Based on the advice, tasks are proposed for the employee to perform. If the employee is not going to perform the task, a reason must be given in the system.;2;Logic and process clearly described. ;No personal data will be processed. ;1;No risks explicitly mentioned. 
detect tax risks in customs declarations until placement under a special procedure;The purpose of this algorithm is to more efficiently select which declarations may have been incorrectly completed. This algorithm focuses on declarations to placement under a special procedure and looks at declarations of goods coming from outside the European Union. It indicates which declarations have a higher risk of fraud or incorrect data. Customs checks companies more or less based on the results. By using this algorithm, declarations are processed more efficiently, resulting in quicker checks and possibly quicker release.;2;Specific, contextualized purpose with clear policy objective. ;The algorithm consists of decision rules created in collaboration with content experts. These decision rules provide estimates of which declarations have a higher risk of fraud or incorrect data in declarations to placement under a special regime. These decision rules are based on 'if-then-else' combinations. An example: if (if) the information we have on a shipment shows that the goods have an abnormal weight, (then) we manually check the declaration and the shipment may be selected for extended inspection. If the goods do not have an abnormal weight (else), we do not stop the shipment. Or at least not based on this criterion.;2;Logic and process clearly described. ;A risk profile is always developed and checked by at least two customs staff before use. This is the 4-eye principle. And once the profile is in use, a weekly check is made for a profile to see how many declarations produce a match. If necessary, the profile can be adjusted. Periodically, Customs checks per profile whether it is still necessary to refine, extend or terminate it. Customs monitors internal and external complaints and incidents, for example if a profile is insufficiently specific and therefore designates too many declarations as higher risk.;2;Risks are clearly stated and contextualized. 
aibobjection;The aim is to process objection letters efficiently and accurately. Optionally by using a large language model to automatically parse and categorise the letters, allowing them to be entered quickly and correctly. Improving efficiency and accuracy in the processing of objection letters, enabling faster responses to submitted objections. This has a positive impact on customer satisfaction and operational efficiency of the relevant government agency or organisation.;2;Specific, contextualized purpose with clear policy objective. ;The system optionally uses a large language model to automatically parse and categorise the content of grievances. The large language model analyses the text, identifies the main grievances and enters them into the appropriate categories in the system. This process also includes automatic input of relevant data into the administration system, minimising manual input.;2;Model type and process is described. ;Potential inaccuracies in automatic processing and categorisation to be mitigated by human control and continuous model improvement.;2;Risks are explicitly defined. 
summarising legal objection opinions;Summaries of existing objection opinions are created. These summaries can be used to enrich the Case Library. This can be done by displaying the core of the case first on the homepage. The Case Library is the internal database for the lawyers of the Legal Bureau (JB). The database contains objection opinions and supports the lawyers in handling new objections.  The summary contains the essence of the objection advice. With its help, lawyers can more quickly assess whether the objection advice matches the information they are looking for. The problem this solves is the long search for the right objection advice, saving time.;2;Specific, contextualized purpose with clear policy objective. ;The algorithm is yet to be developed. In outline, data of objection opinions will be retrieved from the dataset. Based on the guidelines we provided, the language model will create a summary using the algorithm.   OpenAI's generative AI model, gpt-3.5-turbo or gpt-4, will be used via Azure to summarise input texts according to yet-to-be-determined instruction-prompt techniques (e.g. few-shot learning). This model can process textual input and create new texts in natural language according to the instruction provided by the user.;2;Model type and process is described. ;Data is only viewable in a secure environment. Lawyers only use it as a search function. There is, as indicated, a feedback function to correct any errors in the data. In addition, it will be mentioned that the summary was created with generative AI.  The results of summaries will be randomly checked to avoid any incorrect output from the language model (based on the algorithm). This is done in the process of fine-tuning and will be avoided as much as possible from prompt-engineering techniques.  There are no risks to vulnerable groups, exclusion and profiling  ;2;Limitations defined. Algorithm is in development - risks might not be known. 
invoice processing;The aim is to be able to receive and automatically process e-invoices using E-Connect. Automated processing of incoming invoices provides efficiency benefits, error probability is reduced and invoices are checked on various aspects.The impact on citizens is minimal because a citizen does not send an invoice.The impact on businesses is minimal, invoices are automatically checked if an invoice fails the entrepreneur is automatically informed.It is checked whether all mandatory information is included on the invoice, is the addressing correct, has the invoice number occurred before and is the information on the invoice correct.;2;Specific, contextualized purpose with clear policy objective. ;1.    Recognising and reading invoice data2.    Checking and validating invoice data, only correct invoices are validated by the system for the next step. If an invoice is not correct, the supplier receives a message asking him to amend the invoice.3.    Conversion of invoices4. Export to administrative system;1;Process is described, but decision logic and model type are not. ;Minimal risk, content controlled by people.;1;No risks explicitly mentioned. 
improved bicycle traffic flow;Properly prioritise cycle traffic so that all traffic flows better.;1;General purpose stated without specific context or policy objective. ;The algorithm is part of the Bicycle Peloton Module (FPM). The Bicycle Platoon Module consists of both smart software and a camera. The aim is to ensure smooth traffic flow at a given traffic light. The camera is aimed at an area tens of metres away from that traffic light. The software linked to the camera predicts whether cyclists, when they arrive at the traffic light, form a group of at least three cyclists right after each other. If that is the prediction, the cyclists are marked as a 'platoon'. The traffic light jumps to green and the cyclists are given clearance. The software calculates the speed of the cyclists based on the camera images. This also predicts how long the light should be green for the group of cyclists. The advantage is that the traffic light is never too long or too short. Cyclists need to stop less often but other traffic can also flow smoothly.The images are processed real-time on the camera by the software. The images are not stored or transmitted. ;2;Process and input data clearly described. ;Low - data is processed real-time on the camera and not stored. ;1;No risks explicitly mentioned. 
living environment: calculation of fees;Fees are actually compensations for municipal services. The rates are set by the municipal council and are stated in the Fees Regulation. In order to be able to levy fees, municipalities must specify base types and types of fees. Fees are calculated on a base. The base type determines where the base for the fee calculation must be found. The type of fee determines the calculation to arrive at the fee amount. Initiators (citizens and organisations) pay for the services of the municipality as specified in the fees regulation of each municipality.;2;Specific, contextualized purpose with clear policy objective. ;Fixed rate: With this calculation method, nothing is calculated. A basis type is therefore not applicable. Percentage: With this calculation method, a percentage of the basis is calculated. This percentage can be positive (surcharge) or negative (discount). Scales: With this calculation method, one calculation is performed, depending on the scale within which the basis falls. This calculation method is used when there are multiple calculation rules, of which only one can apply. If the basis lies between the minimum and the maximum, this scale is used. The basis is rounded off for the calculation. The factor and the basic amount can be both positive and negative. Disks: With this calculation method, a calculation is performed for each disk, for that part of the basis that falls within the disk. This calculation method is used when a staggered calculation is required. If a part of the basis lies between the minimum and the maximum, that part of the basis is used for the calculation of this disk. The basis is rounded off for the calculation. The factor and the basic amount can be either positive or negative. After the calculation, the amount is rounded off. After rounding, it is checked whether the amount lies between the minimum and maximum amount. If the amount is higher than the maximum, the maximum is used. If the amount is between the minimum and the maximum, the amount is used. If the amount is lower than the minimum, the minimum is used.;2;Process, logic and input data are clearly described. ;Because personal data is used to be able to impose the fees, the AVG applies. Unauthorised persons cannot access data due to the implemented information security. Security risks are controlled by the overall security set up on systems and connections. These meet the requirements. It is possible that the wrong basis is used or that the system setup is not up-to-date or correct. This can result in incorrect fees being imposed. Responsible and authorised employees manually approve all calculated fees before they can be invoiced. This is a human interaction that cannot be skipped. This action is also permanently recorded in the application. Initiators (citizens and organisations) have the right to object to the imposed fees or to appeal against a rejected objection.;2;Risks are clearly described and contextualized. 
mm wave sensing pilot;This involves scientific research with AMS Institute and TU Delft. The algorithm is used to convert signals coming into the mmWave sensor into a number representing the of the number of people in front of the sensor. This is intended to have a more privacy-friendly alternative to pedestrian counting cameras in the city. There is a pilot setting at the Marineterrein.;2;Specific, contextualized purpose with clear policy objective. ;;0;Field left empty. ;;0;Field left empty. 
smart deployment of road inspectors;Rijkswaterstaat's objective is road safety and traffic flow on the road network. Together with its partners, it ensures that lanes are cleared quickly at incidents. By cleverly positioning road inspectors, the response time to incidents can be made as short as possible. As a result, incidents are secured and dealt with as quickly as possible. When dealing with incidents, each party, such as police, fire brigade and ambulance, as well as salvage companies, has its own tasks and responsibilities.;2;Specific, contextualized purpose with clear policy objective. ;;0;Field left empty. ;When deploying the algorithm, the privacy regulations of its own operational staff (road inspectors) were mainly considered. Traces of deployments (only routes and driving times) are kept for the algorithm to learn, but no personal data are linked to this.;1;Vaguely suggests privacy risks. 
detecting risks in customs declarations: introduction and import of non-animal foodstuffs;The purpose of this algorithm is to select consignments for control that enter the European Union, through the territory of the Netherlands, and are imported into the Netherlands. The algorithm focuses on control of consignments containing foodstuffs of non-animal origin. Here, Customs acts in cooperation with the Netherlands Food and Consumer Product Safety Authority (NVWA). Customs checks companies more or less based on the results.;2;Specific, contextualized purpose with clear policy objective. ;The algorithm consists of decision rules created in collaboration with content experts. These decision rules provide estimates of which declarations have a higher risk when introducing and importing food of non-animal origin. These decision rules are based on 'if-then-else' combinations. An example: if (if) the information we have on a consignment shows that the goods have an abnormal weight, (then) the declaration is checked manually and the consignment may be selected for extended inspection. If the goods do not have an abnormal weight (else), we do not stop the shipment. Or at least not based on this criterion.;2;Clearly states the process and input data. ;A risk profile is always checked by a second customs officer (4-eye principle) before use. And once the profile is in use, it is periodically checked how many declarations produce a match. If necessary, the profile can be adjusted. Annually, Customs evaluates per profile whether it is necessary to refine, extend or terminate it. Customs monitors internal and external complaints and incidents, for example if a profile is insufficiently specific and therefore designates too many declarations as higher risk.;2;Risks are explicitly defined. 
youth health care;We want to monitor the development of Utrecht children between 0 and 4 years old. So that we can contribute to them growing up in a healthy and safe way. In doing so, we contribute directly to Healthy Urban Living in Utrecht.;2;Specific, contextualized purpose with clear policy objective. ;;0;Field left empty. ;The Utrecht data scientists, Information and Process Advisors (IPA) and Decentralised Information Security Officers (DISO) within the Utrecht municipality have a controlling and monitoring role in the application of the algorithm, in addition to the employees directly involved. By doing so, we want to prevent the following risks from occurring:- data leak by making personal data of Utrecht residents publicly available- algorithm takes a decision completely independently, without the intervention of an employee and without interpreting the relevant context of the situation- 'function creep' regarding data in the application of the algorithm, causing the algorithm to give a distorted picture of what is going on. This can occur because the same type of data is used when applying the algorithm, and the algorithm uses that as confirmation for what comes out as information;2;Risks explicitly mentioned and contextualized. 
enforcement of liquor and catering law;Targeted inspection of catering establishments for compliance with the Liquor and Catering Act;2;Specific, contextualized purpose with clear policy objective. ;;0;Field left empty. ;The Utrecht data scientists, Information and Process Advisors (IPA) and Decentralised Information Security Officers (DISO) within the Utrecht municipality have a controlling and monitoring role in the application of the algorithm, in addition to the employees directly involved. By doing so, we want to prevent the following risks from occurring:- data leak by making personal data of Utrecht residents publicly available- algorithm takes a decision completely independently, without the intervention of an employee and without interpreting the relevant context of the situation- 'function creep' regarding data in the application of the algorithm, causing the algorithm to give a distorted picture of what is going on. This can occur because the same type of data is used when applying the algorithm, and the algorithm uses that as confirmation of what comes out as information;2;Risks are clearly described and contextualized. 
mutation recognition on agricultural plots;The aim is to get the latest version as high as possible in an efficient way, by splitting the work stock. We achieve this goal by recognising equal plots, keeping the overview updated.   Plots that may have changed are thus viewed as quickly and well as possible by a human employee.   As a result, RFO has its overview updated much faster, so there are fewer errors in the land overview.;2;Specific, contextualized purpose with clear policy objective. ;Step 1. Generate True Orthophoto In Imaging's stereo aerial photos, each area is visible in two or more aerial photos. Using this stereo image, we can see depth in the aerial photo. We use this to create an aerial photo without inversion (perspective): the True Orthophoto.  Step 2. Segmentation agricultural plots, buildings, water, roads, other We use an AI model that looks at the aerial photo. The model divides the aerial photograph and the elevation model into contiguous areas with the following classes: 1. Agricultural parcels 2. Buildings 3. Water 4. Roads 5. Other areas.  Other areas include all parts that do not belong to the other classes, such as trees. The model is trained to recognise this topography based on examples from the Basic Registration of Large-scale Topography.;2;Input and process are clearly described. ;The risk of the algorithm seeing a mutation is mitigated by checking them all by hand.   Differences in operation of the algorithm per area type are reviewed based on cultural-historical landscape type. On this, minor adjustments per area are made to the model. This is explained in a technical report and in an operational report.;2;Risks are clearly stated. 
customisation scan;"
UWV wants to offer services that fit your situation. The Maatwerkscan shows us whether you are at risk of ending up on welfare after the WW. Are you at risk? If so, we will contact you to see what support you need to reduce this risk.
";2;Specific, contextualized purpose with clear policy objective. ;"
From the Maatwerkscan comes a score. This score gives us information about the risk of you having to apply for social assistance benefit after the WW. The higher the score, the higher this risk.

The Maatwerkscan is carried out again every week. Here, some data remain the same, but there are also data that always change. For example, the number of months you will still get WW gets smaller and smaller. As a result, the risk of being on welfare becomes slightly higher each time. It is therefore possible that we will not contact you until you have been on WW benefit for a bit longer.

Have you not yet been invited for an interview, but would like advice? You can always request an interview. UWV helps everyone on WW benefit, regardless of the results of the Maatwerkscan.
";1;Method is somewhat described but lacks logic description and model type. ;"
We ensure that we remain compliant with information security and privacy requirements. We do this in the following ways:

We do not use the results of the Customisation Scan for other purposes.
We continuously work on maintaining the algorithm.
We have other organisations check our compliance with legal and ethical standards.
An external and independent organisation carries out quality checks to test whether the algorithm is careful. This is in addition to the checks our specialist UWV staff do as standard.



Customisation scan is designed so that everyone looking for work is treated in the same way. This is done as follows:

Maatwerkscan processes all data in the same way.
Maatwerkscan does not use personal characteristics such as origin, gender or nationality.


";1;No risks explicitly mentioned. 
participation act benefit;Determining which standard to apply for a resident mbt Participation Act;1;General purpose stated without specific context or policy objective. ;;0;Field left empty. ;The Utrecht data scientists, Information and Process Advisors (IPA) and Decentralised Information Security Officers (DISO) within the Utrecht municipality have a controlling and monitoring role in the application of the algorithm, in addition to the employees directly involved. By doing so, we want to prevent the following risks from occurring:- data leak by making personal data of Utrecht residents publicly available- algorithm takes a decision completely independently, without the intervention of an employee and without interpreting the relevant context of the situation- 'function creep' regarding data in the application of the algorithm, causing the algorithm to give a distorted picture of what is going on. This can occur because the same type of data is used when applying the algorithm, and the algorithm uses that as confirmation of what comes out as information;2;Risks are clearly described and contextualized. 
havank;The purpose of the algorithm is the automated comparison of fingerprints and handprints (hereafter fingerprints). Establishing a person's identity is of great importance in police processes. It is at the heart of investigations. Comparing many fingerprints is impossible and impracticable for a human being. Therefore, fingerprint comparison is automated. This algorithm contributes to efficient and effective policing, increasing the chance of being caught and thus safety. The police use fingerprints to establish or verify a person's identity. This can include suspects, victims of crime, unknown deaths and witnesses. Forensics secures fingerprint traces at crime scenes and uses them to conduct investigations. The aim is to find the donor of the trace for truth-finding in criminal investigations and for evidence. HAVANK contains fingerprints of suspects and convicted persons of crimes punishable by four years or more in prison.;2;Specific, contextualized purpose with clear policy objective. ;"HAVANK converts an image of a fingerprint into an ""arithmetic key"" using an algorithm. This key is stored under a unique registration in a database. The image is also stored under the unique registration. If a new fingerprint is presented to the system then the algorithm will again determine the ""arithmetic key"" and store it under a new unique registration. With this arithmetic key, a comparison is performed with all the arithmetic keys in the database. Using the algorithm, a score is then determined for each comparison.The algorithm fingerprints for identity determination produces a hit-no-hit result. This is done on the basis of a score: if the score is above a certain value then it is a hit, if the score is below a certain value then it is a no-hit. The algorithm traces hand and fingerprints to produce a candidate list of scores. The algorithm is not self-learning.";2;Input and process are clearly described. ;- Only trained and authorised experts have access to the algorithm and fingerprints.- To avoid bias, experts do not know which case they are working on, experts do not know from each other who is working on which case, and experts do not see each other's results.- Automatic results are only generated above a reliable score threshold. A human checks if the data is correct or if there are any possible discrepancies.- The results of the trace comparison algorithm are always assessed by at least three certified experts from the police according to a standardised work process under ISO 17025 accreditation (standard for testing and calibration laboratories). The outcome of the processing is thus the conclusion of three human experts.;1;No risks explicitly mentioned. 
secondary market transaction reporting (smtr);"The Dutch State uses Primary Dealers (PDs). These are banks appointed to purchase, promote and distribute Dutch State Loans (DSLs) and Dutch Treasury Bills (DTCs). A one-year contract is concluded with the PDs. PDs have the exclusive right to participate in the DSTA's DSL auctions and to use the repo and strip facility. PDs also receive a financial remuneration that depends on the quantity of DSLs taken from issues. Against these rights there are also obligations; for instance, PDs are obliged to continuously issue bid and offer prices for DSLs, the so-called quoting obligation. PDs are also obliged to report monthly on activity in the secondary market.The secondary market is the financial market where investors buy and sell existing securities such as bonds from each other. This is in contrast to the primary market, where new securities are sold directly. This algorithm focuses on reporting the activities on this secondary market. It gives the DSTA insight into the trading transactions on part of the secondary market, which provides more information on the liquidity of Dutch government securities.";2;Specific, contextualized purpose with clear policy objective. ;The data are supplied by means of an XML file. The format of the XML file is predefined. A transaction contains the following information: transaction date, ISIN code, type of transaction (buy/sell), nominal value, counterparty, country code, trading system, value date (day on which the transaction takes effect) and trading entity (BIC). The data are automatically loaded into the DSTA's data warehouse. ;1;Logic and process are vaguely described. ;The risks of its use are low. The algorithm does not use personal data. Risk of incorrect content is mitigated by the use of automated content checks. ;2;Mentions possible risks and how they are mitigated. 
detection of attenuations in watercourses;By using the algorithm, we can detect more/faster illegal attenuations. Good water management in the Netherlands is necessary to protect our country from flooding and an excess or shortage of rainwater, for example. A good water level is important for nature conservation, recreation, fishing and water transport, among other things. It is important to detect illegal attenuations as they can disrupt the water system. ;2;Specific, contextualized purpose with clear policy objective. ;The model learns to recognise water on aerial photographs. It looks at the colours on the photos and uses them to determine if there is water. For example: A very dark colour, almost black, may indicate the presence of water. By practising with photos that show water, the model learns what water looks like.When the model has finished learning, we can use it to see where water is on aerial photographs. That way, we can see exactly where ditches are. Then we compare what the model has found with existing data about water. This allows us to see if anything has changed. We check the changes we have found manually to make sure they are attenuations. ;2;Logic and process clearly described. ;With human supervision. There is a working description. Measures are included in the DPIA. ;1;No risks explicitly mentioned. 
directive on administrative coorperation-6 (dac6);"In 2018, the European Commission adopted the DAC6 (""Directive on Administrative Cooperation"") directive. This directive aims to encourage cooperation between European Union member states on unwanted tax avoidance. In the Netherlands, this directive has been incorporated into the International Tax Assistance Act (WIB). This introduced an obligation to report 'cross-border constructions' by intermediaries in particular, for example tax advisers, lawyers or accountants.For more information on the DAC6 directive, see.https://www.belastingdienst.nl/wps/wcm/connect/nl/intermediairs/content/mandatory-disclosure-rules-dac6Around 1,000 notifications per year are expected to involve one or more Dutch taxpayers. A multitude of these have also been received about constructions implemented in the period 25 June 2018 to 31 December 2021. The algorithm puts all these notifications in order of importance. Notifications with the highest risk of tax evasion are put at the top. Conducting supervision is more efficient and effective with the algorithm.";2;Specific, contextualized purpose with clear policy objective. ;The algorithm consists of decision rules created in collaboration with content experts. There are general decision rules and decision rules that apply to a substantial feature. A substantial feature is a feature that, according to the directive, indicates potential tax avoidance. This may involve looking at data from multiple tax resources at the same time, e.g. corporate tax and income tax. Based on the decision rules, the algorithm gives each report a risk score. For each creature characteristic, the notifications with the highest risk score are signalled to a Tax Administration employee who assesses the notification for the need for further investigation. As a result, follow-up actions can be taken, such as asking questions of the intermediary or dealing with the notification when assessing a return of the taxpayer included in the notification.The algorithm is not self-learning. This means that it does not evolve during its use.;2;Logic and process clearly described. ;The algorithm was developed by the Tax Administration and is also maintained internally. Qualitative evaluation of the algorithm takes place periodically. This makes it possible to assess whether the algorithm needs to be improved.The use of the data is tested against the General Data Protection Regulation (AVG). The Tax Administration prevents direct discrimination with the algorithm by not using protected personal data, such as ethnic origin. However, the data 'country of residence' and 'tax resident' are processed. These are not used in the algorithm as an alternative to ethnic origin.For the development of algorithms, the Tax and Customs Administration has drawn up conditions, a quality framework. This contains rules and agreements that were followed when developing the algorithm. The conditions of the Audit Service Rijk (ADR) are leading in this respect. When changes are made to the algorithm, the Tax and Customs Administration checks whether the algorithm still meets the quality requirements.The use of the relevant data is tested against the relevant legislation.The AVG and WIB stipulate that we cannot use more data than necessary. The Inland Revenue regularly reviews whether the data used is still necessary and therefore may be used. If this is not the case, the algorithm is adjusted and this data is also no longer used.The algorithm puts reports about individuals and companies in a specific order. This order is only used in the described process. Outside of that, they are not used, to avoid profiling that is not allowed.;2;Risks are clearly described and contextualized. 
remote sensing area classification based on ai image recognition;By using smart algorithms, we can map and analyse changes in a natural area. This allows us to predict the effect on the environment and take action. Using image recognition on satellite images and analysis, changes in Natura 2000 areas, a European network of protected natural areas, are visualised and mapped in detail. This is done to support ecological purposes, such as nitrogen policy monitoring. The province of South Holland is monitored using various sensors (satellite images, LIDAR, IR, multispectral, microwave, etc.) from satellites, aircraft and helicopters.  Much of this data is available for free. Exploiting such area-wide measurement series can give a big boost to monitoring natural areas. Interpreting remote sensing data into ecologically relevant insights can be an important building block for a digital twin of nature. These measurement sets can serve as the 'skeleton' or framework on which the digital twin can be further built. Drone imagery, combined with species recognition, also provides a means of obtaining highly detailed data. This increases coverage and it allows for better updating within the province. Habitat biodiversity is lower than desired. At European level, it is stipulated that government agencies have the task of improving this in Natura 2000 areas. Using image recognition, changes in these areas are visualised and mapped in detail. This allows plant species to be recognised and monitored, for example to identify the spread of invasive species and take remedial measures against nitrogen. Within nature reserves, certain plant species are sensitive to nitrogen. Excess nitrogen causes these plant species to be displaced by other, less desirable species, such as nettle grasses. This process, such as grassing, can have negative consequences for the biodiversity of dune areas, for example. The resolution of the images is 50 to 30 centimetres of raw data from NSO, with aggregations up to 3-4 metres for ecological applications. There is no impact on people as they are not recognisable on the satellite images (subject to privacy check NSO).;2;Specific, contextualized purpose with clear policy objective. ;Scikit learn: package models open source within Python. Model: Pixed-based random forest for recognising vegetation structures. ;1;Model type is mentioned. Logic and process are only vaguely described. ;The model is 90% watertight. Human intervention (ecologist) is needed, to check things. It is also good to look at drone images additionally. The accuracy is 90% of image recognition with F1 score.;2;Clearly mentions inaccuracy as a limitation. 
tiresias;The aim of Tiresias is to protect the privacy of citizens. This is done by blinding the windscreen of a vehicle, making the occupants unrecognisable.;2;Specific, contextualized purpose with clear policy objective. ;"A machine learning model determines which parts of the image should be blinded. This is done with a special algorithm (a neural network) that creates a 'mask' to mark the areas to be blinded (semantic segmentation). A UNET model [1] is used for this purpose, which is trained to accurately recognise areas such as vehicle windscreens. During training, the algorithm itself learns how to mark windscreens. The image is pre-adjusted to a size of 224x224 pixels (configurable) and the brightness is normalised. As a result, the model produces an image in which all vehicle windscreens are marked.After the algorithm is trained and it is applied, the algorithm does not continue to learn. It will then always give the same output at the same input.Notes for experts:* A UNET model with Resnet18 backbone is used. [2]* The model is trained with a combination of Binary Cross-Entropy (BCE) and Jaccard-loss.[3]Sources:[1] Ronneberger O, Fischer P, Brox T (2015). ""U-Net: Convolutional Networks for Biomedical Image Segmentation"". [2] He, Kaiming; Zhang, Xiangyu; Ren, Shaoqing; Sun, Jian (2016). Deep Residual Learning for Image Recognition. Conference on Computer Vision and Pattern Recognition.[3] MA Rahman and Y Wang (2016). Optimizing intersection-over-union in deep neural networks for image segmentation. International Symposium on Visual Computing.";2;Model type and process is described. ;The entire windscreen is blinded instead of just the people behind it. This is easier and ensures that nothing behind the windscreen is visible, such as faces, clothing or other details. Only the vehicle and the registration number remain visible. ;1;No risks explicitly mentioned. 
locating lampposts;The purpose of the system is to update the registration of lampposts. This registration is used for asset management (including maintenance) of public lighting. The system detects lampposts in 3D point clouds. It then calculates properties of the lamp posts, such as the exact location of the bottom and top of the lamp post, and the angle it makes with the ground.;2;Specific, contextualized purpose with clear policy objective. ;Description of the system architecture:The first step is the semantic segmentation of point clouds. Here, we classify points into regions based on their meaning. We determine whether something is part of a lamppost or not. For this, we use RandLA-Net (QingyongHu/RandLA-Net (github.com)). The next step is to cluster all points that belong to lampposts. We use connected-component labelling for this purpose. We remove noise and eventually arrive at pieces of point clouds that belong to an individual lamppost. For each cluster found, we use prinicipal component analysis to create a fit for each lamp post. From this fit, we can easily derive the properties of the pole. The code for these last two steps can be found on our github: Amsterdam-AI-Team/Urban_PointCloud_Analysis PerformancePerformance first step in data processing (semantic segmentation with RandLA-Net): the intersection-over-union for the lamppost class is 82. Performance second step (identifying individual lampposts): a significant proportion (about a third) of the lampposts found are in reality not lampposts (false positives). These are picked out by humans (see heading 'human monitoring').Performance third step (fit per lamp post): in 91 per cent of cases the fit was correct and in the remaining 9 per cent was corrected by a human.;2;Process, logic and model type clearly described. Input data also mentioned. ;The system is low risk because the data is not very sensitive and the outcomes are checked by people before we use them. Large scale data processingRisk description: Large scale data processing (segmentation of everything that can be seen from the road, sense of being part of a machine, automated system)Frequency: LowDescription of risk mitigation: Communication. We explain that we do not use everything and that everything is controlled by humans.Mitigation status: CompletedLikelihood: LowScale: LowSeverity: LowLocation dataRisk description: Location data (knowing where everything is might be helpful for people with malicious intentions)Frequency: LowMitigation status: Not startedLikelihood: LowScale: LowSeverity: LowNon-discrimination: We expect the model to perform best in areas similar to those the model is trained on (in this case, same shapes lampposts and appearance of the environment). We want to try to keep the impact of (the quality of) the model the same for different groups. Therefore, Amsterdam Oost was chosen as the location for training the model, as this district has a diverse streetscape and population.;2;Risks and limitations are mentioned. 
fingerprint-based identity verification for inclusion in travel document;We deploy the algorithm as technical support for verifying whether two fingerprints come from the same finger of the same person. The fingerprints in question are those recorded in the travel document.;2;Specific, contextualized purpose with clear policy objective. ;A fingerprint matching algorithm compares two fingerprint images and gives a decision of match or no match.;1;Process and input data is vaguely mentioned. Logic and model type are not described. ;No basic security test was taken;1;No risks explicitly mentioned. 
payroll tax risk model - supervision of foreign service providers for payroll taxes (tbd);The Tax Authority supervises the correct and complete withholding and remittance of payroll taxes. Payroll taxes consist of wage tax, national insurance contributions, employee insurance contributions and income-related healthcare insurance contributions, and must be remitted by employers via the payroll tax return. The payroll tax risk model helps Tax and Customs Administration staff monitor proper compliance with legislation relevant to payroll taxes. There are several laws and regulations that affect this supervision. One such law is the Law on Working Conditions for Posted Workers in the EU (WagwEU). This regulates the right to the main conditions of employment for workers who come to work temporarily in the Netherlands. There are a number of administrative obligations that are part of this law. One of these obligations concerns the reporting of workers posted in the Netherlands by the foreign service provider. This is done through a specific online reporting office. The Tax and Customs Administration receives these reports of employees posted in the Netherlands from the Social Insurance Bank to carry out supervision.The algorithm TBD is designed to detect foreign service providers who may have wrongly failed to pay payroll taxes for employees posted in the Netherlands. It can then investigate whether wage taxes are indeed wrongly not remitted. This is done by calling, sending a letter or via an inspection visit, among other things.;2;Specific, contextualized purpose with clear policy objective. ;The algorithm consists of decision rules created in collaboration with content experts and lawyers.The algorithm is not self-learning. This means that it does not evolve while being used.;1;Model type is mentioned. Input data and decision logic not mentioned. ;The use of the data is tested against the General Data Protection Regulation (GDPR). The Tax Administration avoids direct discrimination with the algorithms by using protected personal data, such as ethnic origin, as little as possible.The algorithm TBD does process the nationality of posted employees. However, nationality is not a selection criterion, but is used so that Tax Administration staff can determine which legislation applies when dealing with a signal.The decision rules are reviewed periodically and adjusted if necessary to, among other things, remain compliant with laws and regulations.For the development of algorithms, the Tax and Customs Administration has drawn up conditions (a quality framework). This contains rules and agreements that are followed when developing the algorithm. The conditions of the Audit Department Rijk (ADR) are leading in this respect. When changes are made to one of the algorithms, the Tax and Customs Administration checks whether the algorithms still meet the quality requirements.The use of the relevant data is tested against the relevant legislation. The AVG prescribes that we should not use more data than necessary. This is called data minimisation. The Tax Authority regularly examines whether the data used is still necessary and therefore may be used. If this is not the case, the algorithm is adjusted and this data is also no longer used. ;2;Explicitly states limitations and context. 
authentication biometrics;Tilburg municipality deploys the algorithm to check whether the resident is who he says he is. This allows Tilburg municipality to give the best service to the right residents without making mistakes in this. ;2;Specific, contextualized purpose with clear policy objective. ;Not self-learning;0;No explanation whatsoever. ;Once errors data are processed, problems arise when a resident needs to identify himself at agencies worldwide. ;1;Vaguely suggests incorrect data. 
education inspectorate risk assessment;The Education Inspectorate supervises the quality of education (the 'guarantee function'). From the safeguarding function of supervision, the inspectorate ensures compliance with the Education Act (and the regulations based on it). This is about what the board and the school/college all have to do. Because of this safeguarding function, every year we map out whether there are educational institutions with risks. Because there are very many schools, study programmes and boards in the Netherlands, we do this check partly automatically. To do this, we use an algorithm: the algorithm calculates a risk score for each educational institution.Based on the risk sorting made by the algorithm, manual desk analyses are performed. For the desk analysis, analysts and/or inspectors look at the data used for the algorithm, but also at other things, such as a school guide, for example, or specific reports (e.g. a concerned parent who contacted the inspectorate). If, based on the manual analysis, inspectors think the risks are high and serious, the school or board will be contacted. Inspectors may then also conduct an on-site investigation at the school, programme, or board.;2;Specific, contextualized purpose with clear policy objective. ;It involves a rule-based algorithm. The rules are established with the help of inspectors and analysts, and based on quantitative research. The various data are aggregated to the school/board/institution level and thus the various indicators are calculated. A risk score is then calculated based on the combination of indicator scores from 1-3 years, the limits for what is considered risky, the annual weights and the weightings per indicator. The output of the model is a risk score per school/board/institution.;2;Model type and input is clearly stated. ;Perfect risk estimation is impossible. To keep the risk estimation as good as possible, annual assessments of the quality of risk estimation of the Performance Monitor are carried out. To this end, we examine whether the schools, programmes and institutions with high risk scores are indeed more likely on average to receive an unsatisfactory assessment in the following year. If it turns out that the predictive power is low, we try to make adjustments that ensure better predictive power. Indeed, if it turns out that the risk assessment has insufficient predictive power, then certain institutions may be examined unnecessarily. The time of analysts and inspectors is then not used in the right places (inefficient). Institutions that do have problems may then be left out of the picture.Even more specifically: if certain groups of schools are disproportionately (disproportionately to the actual risks) represented in the high-risk groups, these institutions may be unnecessarily burdened. Even then, there is inefficient use of capacity, and unfair burden on certain schools or boards. Because institutions with higher risk scores are investigated more often, wrong risk estimation can also continue (tunnel vision). Therefore, since September 2023, we have started on-site examinations at randomly selected educational institutions. This allows us to evaluate the quality of risk estimation even better. Indeed, random selection helps prevent tunnel vision.;2;Limitations are defined and contextualized. 
educational outcomes models po and vo;The Education Inspectorate monitors the quality of education. Educational outcomes are a consequence of educational quality. Education that is not good enough leads to educational outcomes that are not good enough. Inspectors use the educational outcomes models when assessing learning outcomes/educational results (as referred to in the WPO, WVO and the Regulations Learning Outcomes PO and VO). With the educational outcomes model, we calculate whether the school succeeds in having pupils achieve sufficient learning outcomes. To do this, we use an average of the learning results of pupils at school. Using the so-called school weighting measure for primary education and the APCG score for secondary education (both calculated by Statistics Netherlands), we also include the characteristics of the entire group of pupils at school. This allows us to take into account the complexity of the pupil population when assessing educational outcomes (see references under the heading 'links to data sources', for more information). A school's calculated educational outcomes are insufficient if they fall below the set standard as described in the Regulations on Learning Outcomes for PO and VO. When a school is selected for examination, the inspector will give a judgement on the standard Results on the basis of the calculated educational results: if the school believes that the calculated educational results do not properly reflect the pupils' learning outcomes, the school can submit its own justification. Through this own justification, the judgement on educational outcomes can still become satisfactory or be described as not assessable. If an inspector judges the educational results to be unsatisfactory during the investigation, the school is given one or more remedial orders. ;2;Specific, contextualized purpose with clear policy objective. ;This is a rule-based algorithm. The rules are laid down in the Regulations Learning Outcomes PO and VO. In PO, two indicators are calculated, one of which is corrected for the school weighting, a measure of the complexity of the pupil population. Both indicators are calculated over three years, taking the weighted average based on pupil numbers. When one or both indicators are below the (corrected) standard, the calculated assessment is unsatisfactory. When both indicators are above the norm, the calculated opinion is sufficient. In VO, four indicators are calculated, each with its own standard. Indicators are calculated by averaging over three years. Corrections are made for three of the four indicators, depending on the background and support needs of pupils at a school. When two of the four indicators are below the norm, the calculated assessment is insufficient.;2;Model type and decision logic clearly described. ;"Every year, the outcomes of the educational outcomes models for primary and secondary education are compared with previous years; based on this comparison, adjustments can be made to the models. Furthermore, context and societal changes are explicitly considered and taken into account in the operation and application of the model, such as, for instance, the effects of corona measures. Evaluations and revisions of models also take place every few years.";1;Limitations only vaguely suggested. No risks explicitly mentioned.
digital life support processing;Awarding benefits to residents who are entitled to them;1;General purpose stated without specific context or policy objective. ;;0;Field left empty. ;The Utrecht data scientists, Information and Process Advisors (IPA) and Decentralised Information Security Officers (DISO) within the Utrecht municipality have a controlling and monitoring role in the application of the algorithm, in addition to the employees directly involved. By doing so, we want to prevent the following risks from occurring:- data leak by making personal data of Utrecht residents publicly available- algorithm takes a decision completely independently, without the intervention of an employee and without interpreting the relevant context of the situation- 'function creep' regarding data in the application of the algorithm, causing the algorithm to give a distorted picture of what is going on. This can occur because the same type of data is used when applying the algorithm, and the algorithm uses that as confirmation of what comes out as information;2;Risks are clearly stated. 